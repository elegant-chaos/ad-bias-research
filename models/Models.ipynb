{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting package metdone\n\bdone\n\n## Package Plan ##\n\n  environment location: /Users/mm06682/.prefix/sw/miniconda\n\n  added / updated specs:\n    - scikit-learn\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    blas-1.0                   |              mkl           6 KB\n    ca-certificates-2019.11.27 |                0         131 KB\n    certifi-2019.11.28         |           py37_0         156 KB\n    conda-4.7.12               |           py37_0         3.0 MB\n    intel-openmp-2019.5        |        intel_281         1.1 MB  intel\n    joblib-0.14.0              |             py_0         201 KB\n    libgfortran-3.0.1          |       h93005f0_2         426 KB\n    llvm-openmp-4.0.1          |       hcfea43d_1         409 KB\n    mkl-2019.5                 |        intel_281       157.8 MB  intel\n    mkl-service-2.3.0          |   py37hfbe908c_0         201 KB\n\n    mkl_random-1.1.0           |   py37ha771720_0         275 KB\n    numpy-1.17.4               |   py37h890c691_0           4 KB\n    numpy-base-1.17.4          |   py37h6575580_0         3.9 MB\n    openssl-1.1.1d             |       h1de35cc_3         3.4 MB\n    scikit-learn-0.21.3        |   py37h27c97d8_0         4.4 MB\n    scipy-1.3.1                |   py37h1410ff5_0        12.4 MB\n    tbb-2019.8                 |        intel_281         287 KB  intel\n    ------------------------------------------------------------\n                                           Total:       188.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  blas               pkgs/main/osx-64::blas-1.0-mkl\n  intel-openmp       intel/osx-64::intel-openmp-2019.5-intel_281\n  joblib             pkgs/main/noarch::joblib-0.14.0-py_0\n  libgfortran        pkgs/main/osx-64::libgfortran-3.0.1-h93005f0_2\n  llvm-openmp        pkgs/main/osx-64::llvm-openmp-4.0.1-hcfea43d_1\n  mkl                intel/osx-64::mkl-2019.5-intel_281\n  mkl-service        pkgs/main/osx-64::mkl-service-2.3.0-py37hfbe908c_0\n  mkl_fft            pkgs/main/osx-64::mkl_fft-1.0.15-py37h5e564d8_0\n  mkl_random         pkgs/main/osx-64::mkl_random-1.1.0-py37ha771720_0\n  numpy              pkgs/main/osx-64::numpy-1.17.4-py37h890c691_0\n  numpy-base         pkgs/main/osx-64::numpy-base-1.17.4-py37h6575580_0\n  scikit-learn       pkgs/main/osx-64::scikit-learn-0.21.3-py37h27c97d8_0\n  scipy              pkgs/main/osx-64::scipy-1.3.1-py37h1410ff5_0\n  tbb                intel/osx-64::tbb-2019.8-intel_281\n\nThe following packages will be UPDATED:\n\n  ca-certificates                               2019.5.15-0 --> 2019.11.27-0\n  certifi                                  2019.6.16-py37_0 --> 2019.11.28-py37_0\n  conda                                        4.7.5-py37_0 --> 4.7.12-py37_0\n  openssl                                 1.1.1c-h1de35cc_1 --> 1.1.1d-h1de35cc_3\n\n\n\nDownloading and Extracting Packages\nscipy-1.3.1          | 12.4 MB   | ##################################### | 100% \nscikit-learn-0.21.3  | 4.4 MB    | ##################################### | 100% \nllvm-openmp-4.0.1    | 409 KB    | ##################################### | 100% \nlibgfortran-3.0.1    | 426 KB    | ##################################### | 100% \nconda-4.7.12         | 3.0 MB    | ##################################### | 100% \nopenssl-1.1.1d       | 3.4 MB    | ##################################### | 100% \nca-certificates-2019 | 131 KB    | ##################################### | 100% \ncertifi-2019.11.28   | 156 KB    | ##################################### | 100% \nmkl_random-1.1.0     | 275 KB    | ##################################### | 100% \nmkl_fft-1.0.15       | 157 KB    | ##################################### | 100% \njoblib-0.14.0        | 201 KB    | ##################################### | 100% \nmkl-service-2.3.0    | 201 KB    | ##################################### | 100% \nmkl-2019.5           | 157.8 MB  | ##################################### | 100% \nintel-openmp-2019.5  | 1.1 MB    | ##################################### | 100%\nblas-1.0             | 6 KB      | ##################################### | 100% \ntbb-2019.8           | 287 KB    | ##################################### | 100% \nnumpy-base-1.17.4    | 3.9 MB    | ##################################### | 100% \nnumpy-1.17.4         | 4 KB      | ##################################### | 100% \nPreparing transactidone\ndone\nEdone\n"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!conda install --yes -c intel scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mm06682/projects/school_projects/fall_2019/software_engineering/google-ad-bias-research/data/processed/final_long.csv')\n",
    "for i,j in zip(*np.where(pd.isnull(df))):\n",
    "    df.iloc[i,j] = \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column = ['age', 'gender', 'education', 'occupation', 'Hispanic', 'race','Political', \n",
    "#             'feelAboutAd', 'image','City', 'State', 'Region','Division', 'page_type', 'relevant']\n",
    "X_column = ['age', 'gender', 'education', 'occupation', 'Hispanic', 'race','Political', \n",
    "            'feelAboutAd', 'image', 'State', 'Region','Division', 'page_type', 'relevant']\n",
    "\n",
    "num_column = ['age','feelAboutAd']\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "\n",
    "for col in X_column:\n",
    "    if col not in num_column:\n",
    "        t = pd.Categorical(df[col])\n",
    "        X_df[col] = t.rename_categories(range(len(t.categories)))\n",
    "    else:\n",
    "        X_df[col] = df[col]\n",
    "\n",
    "y_df = df['rating']\n",
    "\n",
    "\n",
    "X = X_df.values.astype('int32')\n",
    "y = y_df.values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_holdout, y_model, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, test_size=0.2, random_state=0)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(modelName):\n",
    "    if modelName == \"lr\":\n",
    "        model = LogisticRegression(dual=False,\n",
    "                       fit_intercept=True,intercept_scaling=1,class_weight=None,\n",
    "                       random_state=None,solver='liblinear',max_iter=100, \n",
    "                       multi_class='auto',verbose=0,warm_start=False,\n",
    "                       n_jobs=None)\n",
    "        grid_param = {\n",
    "            'penalty':['l1', 'l2'],\n",
    "            'C': [0.01, 0.10, 1.0],\n",
    "        }\n",
    "    elif modelName == \"randomforest\":\n",
    "        model = RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=None,\n",
    "                            min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1, \n",
    "                            random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "        grid_param = {\n",
    "            'n_estimators': [100, 300, 500, 800, 1000],\n",
    "            'min_samples_leaf': [1, 3, 5, 7]\n",
    "        }\n",
    "    elif modelName == \"knn\":\n",
    "        model = KNeighborsClassifier(weights='uniform',algorithm='auto',p=2,metric='minkowski',metric_params=None,\n",
    "                         n_jobs=None)\n",
    "        grid_param ={\n",
    "            'n_neighbors' :[2,5,10,20,30]\n",
    "        }\n",
    "    elif modelName == \"svm\":\n",
    "        model = SVC(kernel='rbf', shrinking=True, \n",
    "         probability=False, verbose=False, \n",
    "         max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "        \n",
    "        grid_param = {\n",
    "            'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "            'gamma': [0.001, 0.01, 0.1, 1]\n",
    "        }\n",
    "        \n",
    "    return model, grid_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start grid search for lr\nBest Param for lr is {'C': 0.01, 'penalty': 'l1'} with 0.4025096525096525 accuracy\nValdiation Accurtacy = 0.42901234567901236\n=============================\nStart grid search for randomforest\nBest Param for randomforest is {'min_samples_leaf': 3, 'n_estimators': 500} with 0.4797297297297297 accuracy\nValdiation Accurtacy = 0.4976851851851852\n=============================\nStart grid search for knn\nBest Param for knn is {'n_neighbors': 20} with 0.41235521235521233 accuracy\nValdiation Accurtacy = 0.44830246913580246\n=============================\nStart grid search for svm\nBest Param for svm is {'C': 1, 'gamma': 0.1} with 0.4333976833976834 accuracy\nValdiation Accurtacy = 0.4591049382716049\n=============================\n"
    }
   ],
   "source": [
    "models = [\"lr\",\"randomforest\",\"knn\",\"svm\"]\n",
    "for m in models:\n",
    "    model, param = getModel(m)\n",
    "    gd_sr = GridSearchCV(estimator=model,param_grid=param,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "    print (\"Start grid search for {}\".format(m))\n",
    "    gd_sr.fit(X_train, y_train)\n",
    "    best_parameters = gd_sr.best_params_\n",
    "    best_result = gd_sr.best_score_\n",
    "    best_estimator = gd_sr.best_estimator_\n",
    "    print (\"Best Param for {} is {} with {} accuracy\".format(m,best_parameters,best_result))\n",
    "    best_estimator.fit(X_train,y_train)\n",
    "    print(\"Validation Accuracy = {}\".format(best_estimator.score(X_test,y_test)))\n",
    "    print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}