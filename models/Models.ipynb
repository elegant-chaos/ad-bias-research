{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#!conda install --yes -c intel scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mm06682/projects/school_projects/fall_2019/software_engineering/google-ad-bias-research/data/processed/final_long.csv')\n",
    "for i,j in zip(*np.where(pd.isnull(df))):\n",
    "    df.iloc[i,j] = \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column = ['age', 'gender', 'education', 'occupation', 'Hispanic', 'race','Political', \n",
    "#             'feelAboutAd', 'image','City', 'State', 'Region','Division', 'page_type', 'relevant']\n",
    "#X_column = ['age', 'gender', 'education', 'occupation', 'Hispanic', 'race','Political', \n",
    " #           'feelAboutAd', 'State', 'Region','Division', 'page_type', 'relevant']\n",
    "\n",
    "X_column = [ 'page_type', 'relevant', 'age', 'feelAboutAd', 'occupation', 'education']\n",
    "\n",
    "num_column = ['age','feelAboutAd']\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "\n",
    "for col in X_column:\n",
    "    if col not in num_column:\n",
    "        t = pd.Categorical(df[col])\n",
    "        X_df[col] = t.rename_categories(range(len(t.categories)))\n",
    "    else:\n",
    "        X_df[col] = df[col]\n",
    "\n",
    "y_df = df['rating']\n",
    "\n",
    "\n",
    "X = X_df.values.astype('int32')\n",
    "y = y_df.values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_holdout, y_model, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, test_size=0.2, random_state=0)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(modelName):\n",
    "    if modelName == \"lr\":\n",
    "        model = LogisticRegression(dual=False,\n",
    "                       fit_intercept=True,intercept_scaling=1,class_weight=None,\n",
    "                       random_state=None,solver='liblinear',max_iter=100, \n",
    "                       multi_class='auto',verbose=0,warm_start=False,\n",
    "                       n_jobs=None)\n",
    "        grid_param = {\n",
    "            'penalty':['l1', 'l2'],\n",
    "            'C': [0.01, 0.10, 1.0],\n",
    "        }\n",
    "    elif modelName == \"randomforest\":\n",
    "        model = RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=None,\n",
    "                            min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1, \n",
    "                            random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "        grid_param = {\n",
    "            'n_estimators': [100, 300, 500, 800, 1000],\n",
    "            'min_samples_leaf': [1, 3, 5, 7]\n",
    "        }\n",
    "    elif modelName == \"knn\":\n",
    "        model = KNeighborsClassifier(weights='uniform',algorithm='auto',p=2,metric='minkowski',metric_params=None,\n",
    "                         n_jobs=None)\n",
    "        grid_param ={\n",
    "            'n_neighbors' :[2,5,10,20,30]\n",
    "        }\n",
    "    elif modelName == \"svm\":\n",
    "        model = SVC(kernel='rbf', shrinking=True, \n",
    "         probability=False, verbose=False, \n",
    "         max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "        \n",
    "        grid_param = {\n",
    "            'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "            'gamma': [0.001, 0.01, 0.1, 1]\n",
    "        }\n",
    "        \n",
    "    return model, grid_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start grid search for lr\nBest Param for lr is {'C': 0.1, 'penalty': 'l1'} with 0.40366795366795366 accuracy\nValidation Accuracy = 0.42746913580246915\n=============================\nStart grid search for randomforest\nBest Param for randomforest is {'min_samples_leaf': 7, 'n_estimators': 800} with 0.4723938223938224 accuracy\nValidation Accuracy = 0.4976851851851852\n=============================\nStart grid search for knn\nBest Param for knn is {'n_neighbors': 2} with 0.41563706563706565 accuracy\nValidation Accuracy = 0.43132716049382713\n=============================\nStart grid search for svm\nBest Param for svm is {'C': 10, 'gamma': 0.1} with 0.44324324324324327 accuracy\nValidation Accuracy = 0.466820987654321\n=============================\n"
    }
   ],
   "source": [
    "models = [\"lr\",\"randomforest\",\"knn\",\"svm\"]\n",
    "for m in models:\n",
    "    model, param = getModel(m)\n",
    "    gd_sr = GridSearchCV(estimator=model,param_grid=param,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "    print (\"Start grid search for {}\".format(m))\n",
    "    gd_sr.fit(X_train, y_train)\n",
    "    best_parameters = gd_sr.best_params_\n",
    "    best_result = gd_sr.best_score_\n",
    "    best_estimator = gd_sr.best_estimator_\n",
    "    print (\"Best Param for {} is {} with {} accuracy\".format(m,best_parameters,best_result))\n",
    "    best_estimator.fit(X_train,y_train)\n",
    "    print(\"Validation Accuracy = {}\".format(best_estimator.score(X_test,y_test)))\n",
    "    print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.46296296296296297\n             importance\nage            0.331928\nfeelAboutAd    0.229282\noccupation     0.139350\neducation      0.115322\npage_type      0.094404\nrelevant       0.089715\n"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,criterion='gini',max_depth=None,\n",
    "                            min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1, \n",
    "                            random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                            min_samples_leaf=7)\n",
    "X_train = pd.DataFrame(X_train, columns = X_df.columns)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(forest.predict(X_test), y_test)))\n",
    "feature_importances = pd.DataFrame(forest.feature_importances_, index = X_train.columns, columns=['importance']).sort_values('importance',ascending=False)\n",
    "print(feature_importances)\n",
    "\n",
    "# After dinner (or in the a.m.), figure out how to subset the dfs on gender here: GOAL: make predictions and check accuracy for each gender in the test set. https://stackoverflow.com/questions/45257635/how-to-subset-data-based-on-another-column-in-python\n",
    "# Not sure if fair ML tools can do this. Also, don't spend too long on this, bc tomorrow the most important thing you can do is write your sections. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting aif360==0.2.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/ec/6497d4ee752611e80a6d5cd51ae89ae8ded02fe6c48a5424db2db7c252af/aif360-0.2.0-py3-none-any.whl (23.4MB)\n\u001b[K     |████████████████████████████████| 23.4MB 1.2MB/s \n\u001b[?25hCollecting numpy<1.16,>=1.14 (from aif360==0.2.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/c3/a69406093c9a780a74964f41cd56b06c0346d686a9b3f392d123a663f5e0/numpy-1.15.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.5MB)\n\u001b[K     |████████████████████████████████| 24.5MB 1.1MB/s \n\u001b[?25hRequirement already satisfied: scikit-learn in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from aif360==0.2.0) (0.21.3)\nCollecting pandas==0.23.3 (from aif360==0.2.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/40/a87f29155cebd25c345e71bd9251f591258f888d553ee42210528546cee8/pandas-0.23.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.0MB)\n\u001b[K     |████████████████████████████████| 14.0MB 1.4MB/s \n\u001b[?25hRequirement already satisfied: scipy in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from aif360==0.2.0) (1.3.1)\nRequirement already satisfied: joblib>=0.11 in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from scikit-learn->aif360==0.2.0) (0.14.0)\nRequirement already satisfied: python-dateutil>=2.5.0 in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from pandas==0.23.3->aif360==0.2.0) (2.8.1)\nRequirement already satisfied: pytz>=2011k in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from pandas==0.23.3->aif360==0.2.0) (2019.3)\nRequirement already satisfied: six>=1.5 in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.23.3->aif360==0.2.0) (1.12.0)\nInstalling collected packages: numpy, pandas, aif360\n  Found existing installation: numpy 1.17.4\n    Uninstalling numpy-1.17.4:\n      Successfully uninstalled numpy-1.17.4\n  Found existing installation: pandas 0.25.3\n    Uninstalling pandas-0.25.3:\n      Successfully uninstalled pandas-0.25.3\nSuccessfully installed aif360-0.2.0 numpy-1.17.4 pandas-0.23.3\nRequirement already satisfied: fairkit-learn in /Users/mm06682/.prefix/sw/miniconda/lib/python3.7/site-packages (1.9)\n"
    }
   ],
   "source": [
    "#!pip install aif360==0.2.0\n",
    "#!pip install fairkit-learn\n",
    "\n",
    "\n",
    "from fklearn.metric_library import UnifiedMetricLibrary, classifier_quality_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After lunch, look at generating some metrics here that show the model would perform differently or is performing differently based on gender. Look through Brittney's examples more closely and the Fair AI examples, too. Writing the code will be simple. You want to get conceptually clear on what you're tryin to show before you do more here. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}